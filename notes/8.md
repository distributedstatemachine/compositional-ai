# Session 8: Forward Evaluation

*Reading: Any minimal example of topological evaluation of a DAG*

---

## The Core Idea

A computation graph is a DAG (Directed Acyclic Graph). **Forward evaluation** is simply executing operations in the right order—an order where every node's inputs are computed before the node itself runs.

```text
    x ──┐
        ├──► [+] ──► [ReLU] ──► y
    w ──┘

To compute y:
  1. Get x and w (inputs)
  2. Compute x + w (the Add node)
  3. Compute ReLU of the sum (the ReLU node)
  4. Output y
```

This ordering is called **topological order**—any order where parents come before children.

---

## Deterministic Semantics

The key property of forward evaluation:

```text
diagram + inputs → outputs (deterministically)
```

Given the same diagram and the same inputs, you always get the same outputs. This is what makes computation graphs useful:

- **Reproducible**: Same inputs = same outputs, every time
- **Inspectable**: You can examine intermediate values
- **Composable**: Small diagrams combine into larger ones

---

## Topological Sort: The Mechanism

Topological sort finds an execution order for a DAG. It's not deep math—it's a practical algorithm:

### The Simple Version

```text
1. Find all nodes with no incoming edges (sources)
2. Process them, then "remove" them from the graph
3. Repeat until all nodes are processed
```

### Kahn's Algorithm (Concrete)

```rust
fn topological_order(graph: &DiGraph) -> Vec<NodeIndex> {
    let mut in_degree: HashMap<NodeIndex, usize> = HashMap::new();
    let mut queue: VecDeque<NodeIndex> = VecDeque::new();
    let mut result: Vec<NodeIndex> = Vec::new();

    // Count incoming edges for each node
    for node in graph.node_indices() {
        let degree = graph.neighbors_directed(node, Incoming).count();
        in_degree.insert(node, degree);
        if degree == 0 {
            queue.push_back(node);  // Sources go in queue
        }
    }

    // Process nodes in order
    while let Some(node) = queue.pop_front() {
        result.push(node);

        // "Remove" this node by decrementing successors' in-degrees
        for successor in graph.neighbors(node) {
            let deg = in_degree.get_mut(&successor).unwrap();
            *deg -= 1;
            if *deg == 0 {
                queue.push_back(successor);
            }
        }
    }

    result
}
```

### Why It Works

The invariant is simple:
- A node enters the queue only when all its predecessors have been processed
- Therefore, when we process a node, all its inputs are ready

---

## Forward Evaluation Algorithm

Once we have topological order, evaluation is straightforward:

```rust
impl Diagram<DiffOp> {
    pub fn forward(&self, inputs: &[Tensor]) -> Vec<Tensor> {
        // Map from node index to computed output tensors
        let mut values: HashMap<NodeIndex, Vec<Tensor>> = HashMap::new();

        // Inject boundary inputs
        for (i, input) in inputs.iter().enumerate() {
            // Store input at the appropriate source node
            let source_node = self.input_nodes[i];
            values.insert(source_node, vec![input.clone()]);
        }

        // Process in topological order
        for node_idx in self.topological_order() {
            // Skip if already computed (was an input node)
            if values.contains_key(&node_idx) {
                continue;
            }

            // Gather inputs from predecessors
            let node_inputs = self.gather_inputs(node_idx, &values);

            // Execute the operation
            let node = &self.graph[node_idx];
            let outputs = node.op.forward(&node_inputs);

            values.insert(node_idx, outputs);
        }

        // Extract boundary outputs
        self.gather_outputs(&values)
    }
}
```

---

## Example: Evaluating a Simple Graph

Consider `y = ReLU(W·x + b)`:

```text
Graph structure:
    [Input x] ──┐
                ├──► [MatMul] ──┐
    [Param W] ──┘               ├──► [Add] ──► [ReLU] ──► [Output y]
                    [Param b] ──┘

Topological orders (multiple valid):
  Option 1: x, W, b, MatMul, Add, ReLU
  Option 2: W, x, b, MatMul, Add, ReLU
  Option 3: b, x, W, MatMul, Add, ReLU

All are valid! The only constraint: MatMul after {x, W}, Add after {MatMul, b}, ReLU after Add.
```

Execution trace (Option 1):

```text
Step 1: x = [1.0, 2.0, 3.0]           (from input)
Step 2: W = [[0.1, 0.2, 0.3], ...]    (from parameters)
Step 3: b = [0.1, 0.1]                (from parameters)
Step 4: MatMul(W, x) = [1.4, ...]     (computed)
Step 5: Add(step4, b) = [1.5, ...]    (computed)
Step 6: ReLU(step5) = [1.5, ...]      (computed, output)
```

---

## The Categorical View

Forward evaluation is a **functor** from diagrams to values:

```text
eval: Diagram → Value
```

This functor preserves structure:

```text
Sequential composition:
  eval(f ; g) = eval(g) ∘ eval(f)

  "Evaluating f then g is the same as composing their evaluations"

Parallel composition:
  eval(f ⊗ g) = (eval(f), eval(g))

  "Evaluating parallel ops gives a tuple of results"
```

In code:

```rust
// Sequential: if diagram = f.then(g), then:
let f_result = f.forward(&inputs);
let g_result = g.forward(&f_result);
// equals:
let fg_result = diagram.forward(&inputs);

// Parallel: if diagram = f.tensor(g), then:
let (f_inputs, g_inputs) = split_inputs(&inputs);
let f_result = f.forward(&f_inputs);
let g_result = g.forward(&g_inputs);
// equals:
let fg_result = diagram.forward(&inputs);  // returns concatenation
```

---

## Why Topological Order Matters

### Correctness
Without proper ordering, you might try to use a value before it's computed:

```text
BAD ORDER: Add, MatMul, x, W
           ↑
           Tries to add values that don't exist yet!
```

### Efficiency
Topological order ensures each node is visited exactly once. No redundant computation.

### Parallelism (Future)
Nodes at the same "level" in topological order can potentially run in parallel:

```text
Level 0: x, W, b        (all independent, can parallelize)
Level 1: MatMul         (depends on level 0)
Level 2: Add            (depends on level 1)
Level 3: ReLU           (depends on level 2)
```

---

## Handling Multiple Outputs

Some operations produce multiple outputs (like `Split`):

```text
    x ──► [Split] ──┬──► a
                    └──► b
```

The evaluation must track which output port connects to which input:

```rust
struct Edge {
    from_node: NodeIndex,
    from_port: usize,      // Which output of the source
    to_node: NodeIndex,
    to_port: usize,        // Which input of the destination
}

fn gather_inputs(&self, node: NodeIndex, values: &HashMap<NodeIndex, Vec<Tensor>>) -> Vec<Tensor> {
    let mut inputs = vec![None; self.graph[node].input_count()];

    for edge in self.incoming_edges(node) {
        let source_outputs = &values[&edge.from_node];
        let value = source_outputs[edge.from_port].clone();
        inputs[edge.to_port] = Some(value);
    }

    inputs.into_iter().map(|x| x.unwrap()).collect()
}
```

---

## DiffOp: Operations for Autodiff

Session 8 introduces `DiffOp`, the operation type for differentiable computation:

```rust
#[derive(Debug, Clone)]
pub enum DiffOp {
    /// Input placeholder (no computation, just passes through)
    Input,

    /// Element-wise addition: a + b
    Add,

    /// Matrix multiplication: A @ B
    MatMul,

    /// Element-wise ReLU: max(0, x)
    ReLU,

    /// Sum all elements to scalar
    SumAll,

    /// Copy input to multiple outputs (for fan-out)
    Copy { n_outputs: usize },
}

impl DiffOp {
    /// Execute the forward pass
    pub fn forward(&self, inputs: &[Tensor]) -> Vec<Tensor> {
        match self {
            DiffOp::Input => vec![inputs[0].clone()],
            DiffOp::Add => vec![inputs[0].add(&inputs[1])],
            DiffOp::MatMul => vec![inputs[0].matmul(&inputs[1])],
            DiffOp::ReLU => vec![inputs[0].relu()],
            DiffOp::SumAll => vec![inputs[0].sum_all()],
            DiffOp::Copy { n_outputs } => {
                vec![inputs[0].clone(); *n_outputs]
            }
        }
    }
}
```

---

## Summary

| Concept | Implementation |
|---------|----------------|
| Execution order | Topological sort (Kahn's algorithm) |
| Forward pass | Process nodes in topo order |
| Value storage | `HashMap<NodeIndex, Vec<Tensor>>` |
| Edge routing | Track (from_node, from_port) → (to_node, to_port) |
| Semantics | Deterministic: same inputs → same outputs |
| Categorical view | Forward eval is a functor preserving composition |

**Key insight**: Forward evaluation is just "run operations in dependency order." The topological sort gives us that order, and then we simply execute each operation with its inputs ready.

---

## Next: Session 9

With forward evaluation working, Session 9 adds the **backward pass**—computing gradients by propagating adjoints in reverse topological order. The backward pass is a functor to the *opposite category*, reversing the direction of information flow.
