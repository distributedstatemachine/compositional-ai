# Session 10: Parameters and SGD Training Loop

*Reading: Minimal SGD / training loop refresher*

---

## The Core Insight

Training is **composition**: forward → loss → backward → update, repeated.

```text
                    ┌─────────────────────────────────────┐
                    │         Training Loop               │
                    │                                     │
    data ──────────▶│  forward → loss → backward → update │──────▶ trained params
                    │      ↑                        │     │
                    │      └────────────────────────┘     │
                    └─────────────────────────────────────┘
```

Parameters are just **inputs we also update**. The gradient tells us which direction to move.

---

## Parameters vs Inputs

In our computation graph:
- **Inputs**: Data that changes each batch (x, y)
- **Parameters**: Weights that persist across batches (W, b)

Both flow into the same graph, but parameters get updated.

```rust
enum DiffOp {
    Input { index: usize },      // Boundary input (data)
    Param { name: String },      // Learnable weight
    // ... other ops
}
```

---

## The Training Loop

```text
for epoch in 0..num_epochs:
    for (x_batch, y_batch) in data:
        1. Forward:  ŷ = model(x_batch, params)
        2. Loss:     L = loss_fn(ŷ, y_batch)
        3. Backward: grads = ∂L/∂params
        4. Update:   params = params - lr * grads
```

This is the **categorical story**:
- Forward pass: functor from Diagram → Values
- Backward pass: functor from Diagram → Op(Diagram)
- Update: endomorphism on parameter space

---

## SGD: Stochastic Gradient Descent

The simplest optimizer:

```text
θ_{t+1} = θ_t - η · ∇L(θ_t)
```

Where:
- `θ_t` = parameters at step t
- `η` = learning rate
- `∇L(θ_t)` = gradient of loss w.r.t. parameters

```rust
/// Simple SGD optimizer
pub struct SGD {
    pub learning_rate: f32,
}

impl SGD {
    pub fn new(learning_rate: f32) -> Self {
        Self { learning_rate }
    }

    /// Update parameters in-place using gradients.
    pub fn step(&self, params: &mut [RTensor], grads: &[RTensor]) {
        for (param, grad) in params.iter_mut().zip(grads.iter()) {
            // θ = θ - lr * grad
            for (p, g) in param.data.iter_mut().zip(grad.data.iter()) {
                *p -= self.learning_rate * g;
            }
        }
    }
}
```

---

## Loss Functions

### Mean Squared Error (MSE)

For regression:

```text
MSE(ŷ, y) = (1/n) Σ (ŷᵢ - yᵢ)²
```

```rust
/// MSE loss: average of squared differences
pub fn mse_loss(prediction: &RTensor, target: &RTensor) -> RTensor {
    let diff = prediction.sub(target);
    let squared = diff.mul(&diff);
    let sum = squared.sum_all();
    sum.scale(1.0 / prediction.data.len() as f32)
}
```

VJP of MSE:
```text
∂MSE/∂ŷᵢ = (2/n)(ŷᵢ - yᵢ)
```

### Cross-Entropy Loss (for classification)

```text
CE(ŷ, y) = -Σ yᵢ · log(ŷᵢ)
```

For softmax outputs with one-hot targets, simplifies to:
```text
CE = -log(ŷ_correct)
```

---

## A Simple Trainable Model

Linear regression: `ŷ = W @ x + b`

```rust
/// A simple linear model for demonstration
pub struct LinearModel {
    /// Weight matrix: (output_dim, input_dim)
    pub weights: RTensor,
    /// Bias vector: (output_dim,)
    pub bias: RTensor,
}

impl LinearModel {
    pub fn new(input_dim: usize, output_dim: usize) -> Self {
        // Initialize with small random values
        Self {
            weights: RTensor::randn(vec![output_dim, input_dim], 0.01),
            bias: RTensor::zeros(vec![output_dim]),
        }
    }

    /// Build computation graph for forward pass
    pub fn forward_graph(&self, graph: &mut DiffGraph) -> (NodeIndex, NodeIndex) {
        let w = graph.param("weights", self.weights.shape.clone());
        let x = graph.input(0, vec![self.weights.shape[1], 1]);
        let wx = graph.matmul(w, x);
        // For simplicity, skip bias for now
        (wx, w)
    }

    pub fn params(&self) -> Vec<&RTensor> {
        vec![&self.weights, &self.bias]
    }

    pub fn params_mut(&mut self) -> Vec<&mut RTensor> {
        vec![&mut self.weights, &mut self.bias]
    }
}
```

---

## The Full Training Flow

```rust
/// Train a model using gradient descent
pub fn train(
    model: &mut LinearModel,
    data: &[(RTensor, RTensor)],  // (input, target) pairs
    epochs: usize,
    learning_rate: f32,
) -> Vec<f32> {
    let optimizer = SGD::new(learning_rate);
    let mut losses = Vec::new();

    for epoch in 0..epochs {
        let mut epoch_loss = 0.0;

        for (x, y_true) in data {
            // 1. Build graph for this forward pass
            let mut graph = DiffGraph::new();
            let x_node = graph.input(0, x.shape.clone());
            let w_node = graph.input(1, model.weights.shape.clone());
            let pred = graph.matmul(w_node, x_node);

            // 2. Add loss computation
            let y_node = graph.input(2, y_true.shape.clone());
            let diff = graph.sub(pred, y_node);
            let sq = graph.mul(diff, diff);
            let loss = graph.sum_all(sq);
            graph.mark_output(loss);

            // 3. Forward pass
            let inputs = vec![x.clone(), model.weights.clone(), y_true.clone()];
            let (outputs, cache) = graph.forward_with_cache(&inputs);
            epoch_loss += outputs[0].as_scalar();

            // 4. Backward pass
            let grads = grad(&graph, &inputs);

            // 5. Update (gradient for weights is at index 1)
            optimizer.step(
                &mut [model.weights.clone()],
                &[grads[1].clone()],
            );
        }

        losses.push(epoch_loss / data.len() as f32);
        println!("Epoch {}: loss = {:.6}", epoch, losses.last().unwrap());
    }

    losses
}
```

---

## Synthetic Data for Testing

```rust
/// Generate synthetic linear regression data
/// y = 2*x + 3 + noise
fn generate_data(n_samples: usize) -> Vec<(RTensor, RTensor)> {
    let mut rng = rand::thread_rng();
    let mut data = Vec::new();

    for _ in 0..n_samples {
        let x = rng.gen::<f32>() * 10.0 - 5.0;  // [-5, 5]
        let noise = rng.gen::<f32>() * 0.1;
        let y = 2.0 * x + 3.0 + noise;

        data.push((
            RTensor::matrix(1, 1, vec![x]),
            RTensor::matrix(1, 1, vec![y]),
        ));
    }

    data
}
```

---

## Training as Composition

The categorical view:

```text
Training = Iterate(Forward ; Loss ; Backward ; Update)
```

Where:
- `Forward: (Params × Data) → Prediction`
- `Loss: (Prediction × Target) → ℝ`
- `Backward: ℝ → Gradients` (functor to opposite category)
- `Update: (Params × Gradients) → Params` (endomorphism)

The composition is:
```text
(Params × Data × Target)
    → (Forward × id)    → (Prediction × Target)
    → Loss              → ℝ
    → Backward          → Gradients
    → Update            → Params
```

---

## Parameter Management

For larger models, we need systematic parameter handling:

```rust
/// Collection of named parameters
pub struct Parameters {
    params: HashMap<String, RTensor>,
}

impl Parameters {
    pub fn new() -> Self {
        Self { params: HashMap::new() }
    }

    pub fn register(&mut self, name: &str, tensor: RTensor) {
        self.params.insert(name.to_string(), tensor);
    }

    pub fn get(&self, name: &str) -> Option<&RTensor> {
        self.params.get(name)
    }

    pub fn get_mut(&mut self, name: &str) -> Option<&mut RTensor> {
        self.params.get_mut(name)
    }

    pub fn iter(&self) -> impl Iterator<Item = (&String, &RTensor)> {
        self.params.iter()
    }

    pub fn iter_mut(&mut self) -> impl Iterator<Item = (&String, &mut RTensor)> {
        self.params.iter_mut()
    }
}
```

---

## Gradient Clipping (Stability)

Prevent exploding gradients:

```rust
impl RTensor {
    /// Clip gradient values to [-max_norm, max_norm]
    pub fn clip(&self, max_norm: f32) -> RTensor {
        let data: Vec<f32> = self.data
            .iter()
            .map(|&x| x.max(-max_norm).min(max_norm))
            .collect();
        RTensor { shape: self.shape.clone(), data }
    }
}
```

---

## Verification: Loss Should Decrease

The key test for training:

```rust
#[test]
fn test_training_decreases_loss() {
    let data = generate_data(100);
    let mut model = LinearModel::new(1, 1);

    let losses = train(&mut model, &data, 10, 0.01);

    // Loss should decrease over training
    assert!(losses.last().unwrap() < losses.first().unwrap());

    // After training, loss should be small
    assert!(*losses.last().unwrap() < 1.0);
}
```

---

## Implementation Checklist

```rust
// In optim.rs:
pub struct SGD {
    learning_rate: f32,
}

impl SGD {
    pub fn new(learning_rate: f32) -> Self;
    pub fn step(&self, params: &mut [RTensor], grads: &[RTensor]);
}

// In ops.rs:
impl RTensor {
    pub fn sub(&self, other: &RTensor) -> RTensor;
    pub fn randn(shape: Vec<usize>, scale: f32) -> RTensor;
    pub fn clip(&self, max_norm: f32) -> RTensor;
}

// In forward.rs:
impl DiffGraph {
    pub fn sub(&mut self, a: NodeIndex, b: NodeIndex) -> NodeIndex;
    pub fn param(&mut self, name: &str, shape: Vec<usize>) -> NodeIndex;
}
```

---

## Summary

| Concept | Implementation |
|---------|----------------|
| Parameters | Inputs that get updated |
| SGD | `θ = θ - lr * grad` |
| Training loop | forward → loss → backward → update |
| Loss function | MSE for regression |
| Verification | Loss decreases over epochs |
| Categorical view | Composition of functors |

**Key insight**: Training is just repeated composition. The gradient tells us which direction makes the loss smaller, and we take a small step in that direction. The categorical structure ensures this all composes correctly.

---

## Next: Session 11

With training working, we move to the **probability track**:
- Stochastic maps (finite Markov kernels)
- Probability as a monoidal category
- Composition of random processes
