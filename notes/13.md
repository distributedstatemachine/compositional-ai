# Session 13: Conditioning and Bayes' Rule

*Reading: Bayes rule + evidence updates*

---

## The Core Insight

**Conditioning is not plain composition**. When we condition on evidence, we:
1. Multiply by the likelihood
2. Renormalize to get a valid distribution

This is fundamentally different from applying a kernel, which preserves normalization automatically.

```text
Composition:     P(Y) = Σₓ P(X=x) · K(Y|X=x)     ← Always normalized

Conditioning:    P(X|Y=y) = P(X) · P(Y=y|X) / P(Y=y)     ← Requires renormalization
                           \_____________/
                              unnormalized
```

---

## Bayes' Rule

### The Formula

```text
P(H|E) = P(E|H) · P(H) / P(E)

Where:
  P(H)   = Prior: belief before evidence
  P(E|H) = Likelihood: how likely is evidence given hypothesis
  P(H|E) = Posterior: belief after evidence
  P(E)   = Evidence: normalizing constant
```

### As a Computation

```rust
use compositional_prob::{Dist, Kernel};

/// Compute posterior P(H|E=e) using Bayes' rule.
///
/// prior: P(H)
/// likelihood: P(E|H) as a kernel H → E
/// evidence_value: the observed value e
pub fn bayes_update(
    prior: &Dist,
    likelihood: &Kernel,
    evidence_value: usize,
) -> Dist {
    // Compute unnormalized posterior: P(H=h) · P(E=e|H=h)
    let mut unnormalized = vec![0.0; prior.p.len()];

    for (h, &prior_h) in prior.p.iter().enumerate() {
        let likelihood_e_given_h = likelihood.k[h][evidence_value];
        unnormalized[h] = prior_h * likelihood_e_given_h;
    }

    // Normalize to get P(H|E=e)
    Dist::from_weights(unnormalized).unwrap()
}
```

---

## Why Conditioning Requires Normalization

### The Problem

When we observe E=e, we're selecting a subset of the probability space. The probabilities in this subset don't sum to 1.

```text
Joint P(H,E):
              E=0    E=1
         ┌────────┬────────┐
  H=0    │  0.3   │  0.1   │  0.4
         ├────────┼────────┤
  H=1    │  0.2   │  0.4   │  0.6
         └────────┴────────┘
             0.5     0.5

Observe E=1:
  P(H=0, E=1) = 0.1
  P(H=1, E=1) = 0.4
  Sum = 0.5 ≠ 1

After normalization:
  P(H=0 | E=1) = 0.1 / 0.5 = 0.2
  P(H=1 | E=1) = 0.4 / 0.5 = 0.8
```

### Contrast with Composition

When we apply a kernel K to a distribution P:

```text
Q(y) = Σₓ P(x) · K(y|x)
```

Each K(·|x) sums to 1, and P sums to 1, so Q automatically sums to 1. No normalization needed!

---

## Implementing Conditioning

### In a Bayesian Network

```rust
use compositional_prob::{BayesNet, Dist};
use std::collections::HashMap;

impl BayesNet {
    /// Compute P(query | evidence) via enumeration.
    pub fn condition(
        &self,
        query_var: usize,
        evidence: &HashMap<usize, usize>,
    ) -> Dist {
        let joint = self.full_joint();
        let n_states = self.var_states[query_var];
        let mut unnormalized = vec![0.0; n_states];

        // Sum over all assignments consistent with evidence
        for (idx, &prob) in joint.probs.iter().enumerate() {
            let assignment = joint.decode(idx);

            // Check if this assignment matches evidence
            let matches_evidence = evidence
                .iter()
                .all(|(&var, &val)| assignment[var] == val);

            if matches_evidence {
                unnormalized[assignment[query_var]] += prob;
            }
        }

        // Normalize
        Dist::from_weights(unnormalized).unwrap()
    }
}
```

### The Normalization Constant

The denominator P(E) is the **marginal likelihood** or **evidence**:

```text
P(E=e) = Σₕ P(H=h) · P(E=e|H=h)
```

Computing this is often the hard part of Bayesian inference!

---

## Sequential Updates

### Multiple Evidence

When we observe multiple pieces of evidence, we can update sequentially:

```text
P(H|E₁,E₂) ∝ P(E₂|H,E₁) · P(E₁|H) · P(H)
```

Or equivalently:

```text
P(H|E₁,E₂) ∝ P(E₂|H,E₁) · P(H|E₁)
```

The posterior from the first update becomes the prior for the second.

```rust
/// Sequential Bayesian updates.
pub fn sequential_update(
    prior: &Dist,
    observations: &[(Kernel, usize)],  // (likelihood, observed_value)
) -> Dist {
    let mut current = prior.clone();

    for (likelihood, evidence_value) in observations {
        current = bayes_update(&current, likelihood, *evidence_value);
    }

    current
}
```

---

## Exact vs Approximate Inference

### Exact Inference

For small, finite state spaces, we can compute posteriors exactly:

```rust
/// Exact inference by enumeration.
/// Complexity: O(∏ᵢ |Xᵢ|) - exponential in number of variables
pub fn exact_inference(
    net: &BayesNet,
    query: usize,
    evidence: &HashMap<usize, usize>,
) -> Dist {
    net.condition(query, evidence)
}
```

This is fine when:
- Few variables (< 20)
- Small state spaces (binary or small discrete)
- Query is simple (single variable)

### When Exact Is Impractical

- Many variables: 2³⁰ ≈ 10⁹ states
- Large state spaces: continuous variables
- Complex queries: multiple query variables

In these cases, approximate methods like **importance sampling** are needed.

---

## Importance Sampling

### The Core Idea

When we can't enumerate all states, we can **sample** to estimate expectations:

```text
E_p[f(X)] ≈ (1/n) Σᵢ f(xᵢ)   where xᵢ ~ p
```

But what if sampling from p is hard? **Importance sampling** lets us sample from an easier proposal distribution q and reweight:

```text
E_p[f(X)] = Σₓ p(x) · f(x)
          = Σₓ q(x) · [p(x)/q(x)] · f(x)
          = E_q[w(X) · f(X)]

where w(x) = p(x) / q(x)  (importance weight)
```

### Self-Normalized Importance Sampling

In practice, we often only know p up to a normalizing constant. Self-normalized IS handles this:

```text
E_p[f(X)] ≈ Σᵢ wᵢ · f(xᵢ) / Σᵢ wᵢ
```

```rust
use compositional_prob::{Dist, importance_sample};

// Target: hard distribution we want to estimate
let target = Dist::new(vec![0.1, 0.2, 0.3, 0.4]).unwrap();

// Proposal: easy to sample from
let proposal = Dist::uniform(4);

// Estimate E[X]
let f = |x: usize| x as f32;
let result = importance_sample(&target, &proposal, f, 1000, Some(42));

println!("Estimated mean: {:.3}", result.estimate);  // ≈ 2.0
println!("Effective sample size: {:.1}", result.effective_sample_size);
```

### Effective Sample Size

Not all samples are equally useful. The **effective sample size (ESS)** measures how many "equivalent" uniform-weight samples we have:

```text
ESS = (Σᵢ wᵢ)² / Σᵢ wᵢ²
```

- ESS = n when all weights are equal (proposal = target)
- ESS ≪ n when weights are highly variable (poor proposal)

Low ESS indicates the proposal doesn't match the target well.

### Likelihood Weighting for Bayesian Networks

**Likelihood weighting** is importance sampling specialized for Bayesian networks:

1. **Forward sample** non-evidence variables from their conditionals
2. **Fix** evidence variables to observed values
3. **Weight** = product of P(evidence | parents)

```rust
use compositional_prob::{sprinkler_network, likelihood_weighting};
use std::collections::HashMap;

let net = sprinkler_network();

// Query P(Rain | WetGrass=true)
let mut evidence = HashMap::new();
evidence.insert(3, 1);  // WetGrass = true

let approx = likelihood_weighting(&net, 2, &evidence, 10000, Some(42));
println!("P(Rain | WetGrass=true) ≈ [{:.3}, {:.3}]", approx.p[0], approx.p[1]);
```

### Why Likelihood Weighting Works

The proposal distribution is the prior (no evidence):
```text
q(x) = P(X)  (forward sampling from the network)
```

The target is the posterior:
```text
p(x) = P(X | E=e) = P(X, E=e) / P(E=e)
```

The importance weight becomes:
```text
w(x) = p(x) / q(x) = P(X, E=e) / [P(X) · P(E=e)]
     ∝ P(E=e | X)  (likelihood of evidence given sample)
```

---

## The Categorical Perspective

### Conditioning as a Two-Step Process

1. **Restrict**: Multiply joint by indicator function for evidence
2. **Normalize**: Divide by marginal probability of evidence

```text
P(X|E=e) = P(X,E=e) / P(E=e)
         = [P(X) · P(E=e|X)] / [Σₓ P(X=x) · P(E=e|X=x)]
```

### Not a Morphism!

Conditioning is **not** a morphism in FinStoch because:
- It's not defined for all inputs (P(E) could be 0)
- It doesn't preserve composition in the expected way

However, conditioning can be expressed using:
- **Disintegration**: Decomposing joint into conditional and marginal
- **Bayesian inversion**: A categorical way to express Bayes' rule

---

## Example: Medical Diagnosis

```rust
use compositional_prob::{Dist, Kernel};

fn medical_diagnosis() {
    // Disease prevalence: P(Disease)
    let prior = Dist::new(vec![0.99, 0.01]).unwrap();  // 1% have disease

    // Test accuracy: P(Test | Disease)
    let test = Kernel::new(vec![
        vec![0.95, 0.05],  // Healthy: 5% false positive
        vec![0.10, 0.90],  // Diseased: 90% true positive
    ]).unwrap();

    // Patient tests positive
    let posterior = bayes_update(&prior, &test, 1);

    println!("Prior P(Disease):        [{:.4}, {:.4}]", prior.p[0], prior.p[1]);
    println!("Posterior P(D|Test=+):   [{:.4}, {:.4}]", posterior.p[0], posterior.p[1]);

    // Despite positive test, disease still unlikely!
    // P(D|+) = (0.01 × 0.90) / (0.99 × 0.05 + 0.01 × 0.90)
    //        = 0.009 / 0.0585 ≈ 0.154
}
```

This demonstrates the **base rate fallacy**: a positive test doesn't mean you likely have the disease if the disease is rare!

---

## Summary

| Concept | Formula | Implementation |
|---------|---------|----------------|
| Prior | P(H) | `Dist` |
| Likelihood | P(E\|H) | `Kernel` |
| Evidence | P(E) = Σₕ P(H=h)·P(E\|H=h) | Sum of unnormalized |
| Posterior | P(H\|E) = P(E\|H)·P(H)/P(E) | Normalize after multiply |
| Sequential | P(H\|E₁,E₂) ∝ P(E₂\|H)·P(H\|E₁) | Chain updates |
| Importance Sampling | E_p[f] ≈ Σᵢ wᵢ·f(xᵢ) / Σᵢ wᵢ | `importance_sample` |
| Likelihood Weighting | Sample prior, weight by evidence | `likelihood_weighting` |

**Key insight**: Conditioning requires renormalization because observing evidence restricts the probability space. This is fundamentally different from kernel composition, which preserves normalization automatically.

When exact inference is intractable, importance sampling provides unbiased estimates by sampling from a proposal distribution and reweighting.

---

## Next: Session 14

With conditioning understood, Session 14 explores:
- **Interventions** via do-calculus
- **do(X=x)** vs **observing X=x**
- Causal vs observational distributions
