# Session 21: Capstone — Rust-Native Agent Framework

## Overview

This is the capstone project. Everything built in Sessions 1-20 culminates in a **Rust-native agent framework** that provides compile-time guarantees impossible in Python frameworks like Agentica.

**Key Insight**: We use **Yoneda-style capabilities** as the foundation — agents are characterized by what requests they can handle, not by hardcoded trait names. This enables extensibility without modifying core code.

## Competitive Analysis: Agentica

### What Agentica Does Well

| Feature | How It Works |
|---------|--------------|
| **Scope-based tool access** | Pass runtime objects (functions, variables, types) directly to agents |
| **RPC bridge** | Scoped functions execute in your runtime with full access |
| **Object proxying** | Return values as lightweight proxies, pass by reference |
| **Type validation** | Runtime validation of return types against annotations |
| **Sandboxed REPL** | Agent writes Python code in isolated environment |
| **Async-first** | Top-level await support in sandbox |

### Agentica's Limitations

| Limitation | Impact |
|------------|--------|
| **Runtime sandbox** | Performance overhead, WASM-based isolation |
| **Runtime type checking** | Errors discovered at execution, not compile time |
| **No parallel safety proofs** | `asyncio` + hope, no `Send/Sync` guarantees |
| **No arity enforcement** | Can wire wrong number of tools to agent |
| **Limited numerics** | Cannot work with torch tensors, numpy arrays, pandas |
| **No composition verification** | Tool chains validated at runtime only |
| **Single-language** | Python only, no polyglot support |

### What We Do Better

| Our Advantage | How |
|---------------|-----|
| **Compile-time capability checking** | `S: HasDatabase + HasLLM` checked by rustc |
| **Zero-cost isolation** | Borrow checker as sandbox, no WASM overhead |
| **Proven parallel safety** | `Send + Sync` proofs, not hope |
| **Arity enforcement** | Operads catch wrong input counts |
| **Type-level composition** | `Then<A, B>` validated at compile time |
| **Zero-cost tracing** | Const generics, compiled out in release |
| **Extensible capabilities** | Yoneda-style Request/Handles, no core changes needed |

## Architecture: Using Yoneda-Style Capabilities

### Why Yoneda Over Hardcoded Traits

**Problem with hardcoded traits:**
```rust
// Must define new trait for each capability
trait HasDatabase { fn db(&self) -> &dyn Database; }
trait HasCache { fn cache(&self) -> &dyn Cache; }
trait HasVectorDB { fn vector_db(&self) -> &dyn VectorDB; }
// Endless proliferation...
```

**Yoneda insight:**
> A capability is defined by what requests it can handle, not by a name.

Instead of "is this a Database?", we ask "can this handle `SqlQuery`?"

```rust
// Define a new request type — no changes to core needed!
struct VectorSearch { embedding: Vec<f32>, top_k: usize }

impl Request for VectorSearch {
    type Response = Vec<(String, f32)>;
    fn name() -> &'static str { "VectorSearch" }
}

// Any capability that implements Handles<VectorSearch> can be discovered
scope.can_handle::<VectorSearch>()  // Yoneda-style discovery
```

### Core Capability Types (from `core/capability.rs`)

```rust
/// A request defines an operation and its response type.
/// This is the "morphism" in the Yoneda sense.
pub trait Request: Send + 'static {
    type Response: Send + 'static;
    fn name() -> &'static str;
}

/// A capability that handles requests of type R.
/// "Handles<R>" = "has a morphism from R into this capability"
pub trait Handles<R: Request>: Capability {
    fn handle(&self, req: R) -> Result<R::Response, CapabilityError>;
}

/// Registry that dispatches requests to handlers.
pub struct CapabilityScope {
    handlers: HashMap<TypeId, Box<dyn AnyHandler>>,
}

impl CapabilityScope {
    /// Yoneda-style discovery: can this scope handle request type R?
    pub fn can_handle<R: Request>(&self) -> bool;

    /// Dispatch a request to its handler
    pub fn dispatch<R: Request>(&self, req: R) -> Result<R::Response, CapabilityError>;

    /// Merge two scopes (coproduct-style)
    pub fn merge(self, other: Self) -> Self;
}
```

## Gap Analysis: What We Need to Build

### Gap 1: Tool Abstraction Using Request/Handles

**Current state**: We have `Request` and `Handles` traits.
**Needed**: A `Tool` type that wraps capabilities and integrates with LLM tool-calling.

```rust
/// A tool is a named capability that can be invoked by an LLM.
pub struct Tool<R: Request> {
    name: String,
    description: String,
    _phantom: PhantomData<R>,
}

/// Request for invoking a tool by name (dynamic dispatch)
pub struct ToolInvoke {
    pub tool_name: String,
    pub args: serde_json::Value,
}

impl Request for ToolInvoke {
    type Response = serde_json::Value;
    fn name() -> &'static str { "ToolInvoke" }
}

/// Tool registry using CapabilityScope
pub struct ToolRegistry {
    scope: CapabilityScope,
    tool_schemas: HashMap<String, ToolSchema>,  // For LLM function calling
}

impl ToolRegistry {
    /// Register a tool (capability) for a specific request type
    pub fn register<C, R>(&mut self, name: &str, description: &str, capability: Arc<C>)
    where
        C: Handles<R> + 'static,
        R: Request + Serialize;  // Args must be serializable for LLM

    /// Get tool schemas for LLM function calling
    pub fn schemas(&self) -> Vec<ToolSchema>;

    /// Invoke a tool by name
    pub fn invoke(&self, name: &str, args: serde_json::Value) -> Result<serde_json::Value, CapabilityError>;
}
```

### Gap 2: LLM Client Abstraction

**Needed**: LLM abstraction that supports tool calling.

```rust
/// LLM completion request with optional tools
pub struct LlmRequest {
    pub messages: Vec<Message>,
    pub tools: Option<Vec<ToolSchema>>,
    pub max_tokens: usize,
}

impl Request for LlmRequest {
    type Response = LlmResponse;
    fn name() -> &'static str { "LlmRequest" }
}

pub enum LlmResponse {
    Text(String),
    ToolCall { name: String, args: serde_json::Value },
    ToolCalls(Vec<ToolCallRequest>),
}

/// Any LLM backend implements Handles<LlmRequest>
pub struct AnthropicClient { api_key: String }
pub struct OpenAIClient { api_key: String }

impl Handles<LlmRequest> for AnthropicClient {
    fn handle(&self, req: LlmRequest) -> Result<LlmResponse, CapabilityError>;
}
```

### Gap 3: Agent Loop Using Computation Trait

**Current state**: We have `Computation` trait in `tracing.rs`.
**Needed**: Agent loop that uses `Computation` for traceable execution.

```rust
use compositional_core::tracing::{Computation, Traced};

/// The core agent loop as a Computation
pub struct AgentLoop<S> {
    scope: Arc<S>,
    tools: ToolRegistry,
    config: AgentConfig,
}

impl<S> Computation for AgentLoop<S>
where
    S: Handles<LlmRequest> + Send + Sync + 'static,
{
    type Input = AgentTask;
    type Output = AgentResult;

    async fn run(&self, input: Self::Input) -> Result<Self::Output, CoreError> {
        // 1. Send task to LLM with tool schemas
        // 2. If LLM returns tool call, execute via ToolRegistry
        // 3. Loop until LLM returns final answer
        // 4. Return result with execution trace
    }
}

/// Traced agent with zero-cost tracing
pub type TracedAgent<S, const ENABLED: bool> = Traced<AgentLoop<S>, ENABLED>;
```

### Gap 4: Multi-Agent Orchestration Using Operads

**Current state**: We have `WiringPlan` in `operad.rs`.
**Needed**: Orchestrator that validates multi-agent pipelines.

```rust
use compositional_core::operad::{Operation, WiringPlan, OperadError};

/// Define agents as operations with explicit arity
pub fn agent_operation(name: &str, tool_count: usize) -> Operation {
    Operation::new(name, tool_count)
        .with_inputs(vec![Shape::json(); tool_count])  // Tool outputs
        .with_outputs(vec![Shape::text()])              // Agent response
}

/// Orchestrator validates agent wiring before execution
pub struct Orchestrator {
    plan: WiringPlan,
    agents: Vec<Arc<dyn Agent>>,
}

impl Orchestrator {
    /// Validate that all agents receive correct number of inputs
    pub fn validate(&self) -> Result<(), OperadError>;

    /// Execute the multi-agent pipeline
    pub async fn execute(&self, input: &str) -> Result<String, AgentError>;
}
```

### Gap 5: Async Tool Execution with ParallelAgents

**Current state**: We have `ParallelAgents` in `parallel.rs`.
**Needed**: Integration with async tool execution.

```rust
use compositional_core::parallel::{ParallelAgents, Combiner};

/// Tools as agents for parallel execution
impl<R: Request> Agent for Tool<R>
where
    R: Clone + Send + 'static,
    R::Response: Send + 'static,
{
    type Input = R;
    type Output = R::Response;
    type Error = CapabilityError;

    async fn run(&self, input: Self::Input) -> Result<Self::Output, Self::Error> {
        self.capability.handle(input)
    }
}

/// Fan-out multiple tool calls in parallel
pub async fn parallel_tool_calls<R: Request>(
    tools: Vec<Tool<R>>,
    inputs: Vec<R>,
) -> Vec<Result<R::Response, CapabilityError>> {
    let parallel = ParallelAgents::new(tools);
    parallel.run_all(inputs).await
}
```

### Gap 6: Execution Trace as Diagram

**Current state**: We have `Diagram` in `diagram.rs` and `TraceNode` in `tracing.rs`.
**Needed**: Convert agent execution into inspectable diagram.

```rust
use compositional_core::diagram::{Diagram, Node};

/// Agent operation for diagram representation
#[derive(Clone, Debug)]
pub enum AgentOp {
    LlmCall { model: String, prompt_tokens: usize },
    ToolCall { name: String, duration_ms: u64 },
    Decision { condition: String },
}

/// Build execution trace as a diagram
impl AgentLoop {
    pub fn to_diagram(&self, trace: &AgentTrace) -> Diagram<AgentOp> {
        // Convert execution trace to string diagram
        // Enables visualization and analysis
    }
}
```

## Comparison Table: Agentica vs Our Framework

| Feature | Agentica (Python) | Compositional (Rust) |
|---------|-------------------|----------------------|
| **Type checking** | Runtime | Compile-time |
| **Sandbox** | WASM (overhead) | Borrow checker (zero-cost) |
| **Parallel safety** | `asyncio` | `Send + Sync` proofs |
| **Tool registration** | Dict-based | `Handles<R>` trait |
| **Capability discovery** | Runtime introspection | `can_handle::<R>()` (Yoneda) |
| **Arity enforcement** | None | Operad validation |
| **Tracing overhead** | Always on | Const generic (compiled out) |
| **Composition** | Runtime dict merge | `scope.merge()` (coproduct) |
| **Extension** | Modify SDK | Define new `Request` type |
| **Tensor support** | None | Full `Shape` system |

## Implementation Checklist

### Phase 1: Core Agent Types
- [ ] `Tool<R>` wrapper for capabilities
- [ ] `ToolRegistry` using `CapabilityScope`
- [ ] `ToolSchema` generation for LLM function calling

### Phase 2: LLM Integration
- [ ] `LlmRequest` and `LlmResponse` types
- [ ] `AnthropicClient` implementing `Handles<LlmRequest>`
- [ ] Message history management

### Phase 3: Agent Loop
- [ ] `AgentLoop` implementing `Computation`
- [ ] Tool calling loop (call until final answer)
- [ ] `TracedAgent` with zero-cost tracing

### Phase 4: Multi-Agent
- [ ] `Orchestrator` using `WiringPlan`
- [ ] Parallel tool execution via `ParallelAgents`
- [ ] Capability delegation between agents

### Phase 5: Observability
- [ ] Execution trace as `Diagram<AgentOp>`
- [ ] Render trace to ASCII/DOT
- [ ] Token usage tracking

## Example: Complete Agent

```rust
use compositional_agents::{
    AgentLoop, Tool, ToolRegistry, TracedAgent,
    scope::{CapabilityScope, Handles, Request},
};

// 1. Define custom request types (extensible without modifying core)
struct WebSearch { query: String }
impl Request for WebSearch {
    type Response = Vec<SearchResult>;
    fn name() -> &'static str { "WebSearch" }
}

struct Calculator { expression: String }
impl Request for Calculator {
    type Response = f64;
    fn name() -> &'static str { "Calculator" }
}

// 2. Implement capabilities
struct BraveSearchClient { api_key: String }
impl Handles<WebSearch> for BraveSearchClient {
    fn handle(&self, req: WebSearch) -> Result<Vec<SearchResult>, CapabilityError> {
        // Call Brave Search API
    }
}

struct MathEvaluator;
impl Handles<Calculator> for MathEvaluator {
    fn handle(&self, req: Calculator) -> Result<f64, CapabilityError> {
        // Evaluate expression
    }
}

// 3. Build scope with Yoneda-style registration
let mut scope = CapabilityScope::new();
scope.register::<BraveSearchClient, WebSearch>(Arc::new(BraveSearchClient { api_key }));
scope.register::<MathEvaluator, Calculator>(Arc::new(MathEvaluator));
scope.register::<AnthropicClient, LlmRequest>(Arc::new(anthropic));

// 4. Yoneda-style discovery
assert!(scope.can_handle::<WebSearch>());
assert!(scope.can_handle::<Calculator>());
assert!(scope.can_handle::<LlmRequest>());

// 5. Build tool registry
let mut tools = ToolRegistry::new();
tools.register::<WebSearch>("search", "Search the web for information");
tools.register::<Calculator>("calculate", "Evaluate a mathematical expression");

// 6. Create traced agent (tracing compiled out in release)
let agent = TracedAgent::<_, false>::new(AgentLoop::new(scope, tools));

// 7. Execute with compile-time guarantees
let result = agent.run(AgentTask {
    prompt: "What is the population of France divided by 2?".into(),
}).await?;

// 8. Inspect execution trace as diagram
let diagram = agent.to_diagram(&result.trace);
println!("{}", diagram.render_ascii());
```

## The Rust Advantage: Compile-Time Safety

### What Rust Catches at Compile Time

```rust
// 1. Missing capability → compile error
fn agent_needs_db<S: Handles<SqlQuery>>(scope: &S) { ... }
agent_needs_db(&scope);  // ERROR if scope doesn't handle SqlQuery

// 2. Wrong arity → operad validation error
let plan = WiringPlan::new(agent_expecting_3_tools)
    .with_inner(vec![tool1, tool2]);  // Only 2!
plan.validate()?;  // ERROR: ArityMismatch

// 3. Thread safety → compile error
fn parallel_agents<S: Send + Sync>(scope: Arc<S>) { ... }
parallel_agents(Arc::new(rc_scope));  // ERROR: Rc is not Send

// 4. Lifetime escape → compile error
fn bad() {
    let scope = Scope::new();
    let agent = Agent::new(&scope);
    std::mem::forget(agent);  // ERROR: can't outlive scope
}
```

### What Agentica Catches at Runtime

```python
# 1. Missing capability → runtime KeyError
scope = {"db": database}
agent.call(scope)  # KeyError: 'cache' at runtime

# 2. Wrong arity → runtime error (or silent bug)
agent.delegate([tool1, tool2])  # No arity checking

# 3. Thread safety → race condition (discovered in production)
asyncio.gather(agent1.run(), agent2.run())  # Hope for the best

# 4. Type mismatch → runtime TypeError
result = agent.call()  # TypeError at runtime
```

## Summary

| Component | Core Abstraction | Agent Framework Use |
|-----------|------------------|---------------------|
| `Shape` | Type-level tensor dims | Tool I/O type checking |
| `Diagram` | String diagram data | Execution trace visualization |
| `Capability` + `Handles<R>` | Yoneda-style extensibility | Tool registration & discovery |
| `CapabilityScope` | Request dispatch registry | Agent scope management |
| `Operation` + `WiringPlan` | Operad arity enforcement | Multi-tool orchestration |
| `ParallelAgents` | Runtime tensor product | Concurrent tool execution |
| `Traced<C, ENABLED>` | Zero-cost tracing | Debug/release mode switching |
| `Computation` trait | Async computation abstraction | Agent loop implementation |

## Key Design Decisions

1. **Yoneda-style capabilities** over hardcoded traits — enables extensibility
2. **Operads for arity** — catches wrong input counts before execution
3. **Borrow checker for isolation** — zero-cost sandboxing
4. **Const generics for tracing** — zero overhead in release builds
5. **`Computation` trait for agents** — unified async abstraction

## Next Steps

1. Implement `agents` crate with the architecture above
2. Write comprehensive examples showing Rust vs Python advantages
3. Benchmark against Agentica for performance comparison
4. Document the Yoneda-style pattern for users

## Reading

- `docs/rust-native-agents.md` — Design document
- `docs/agentica-improvements.md` — Competitive analysis
- Agentica docs: https://docs.symbolica.ai — Reference implementation
- Our `core/capability.rs` — Yoneda implementation
