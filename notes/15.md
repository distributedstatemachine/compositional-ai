# Session 15: Pregroup Grammars and Type Reductions

## Overview

Pregroup grammars provide a **type-theoretic** approach to syntax where grammaticality is type reduction. This is the foundation of DisCoCat (Distributional Compositional Categorical) models that combine grammatical structure with distributional semantics.

## Key Concepts

### Pregroup Types

**Basic Types:**
- `N` — noun (entity type)
- `S` — sentence (truth value type)

**Adjoint Types:**
- `Nʳ` — right adjoint of N (expects N on the right)
- `Nˡ` — left adjoint of N (expects N on the left)
- `Sʳ`, `Sˡ` — adjoints of S

**Type Hierarchy:**
```
      N
     / \
   Nˡ   Nʳ

      S
     / \
   Sˡ   Sʳ
```

### Reduction Rules

The key insight: types "cancel" like fractions!

**Right reduction:** `N · Nʳ → 1` (noun followed by "wants noun on right" cancels)

**Left reduction:** `Nˡ · N → 1` ("wants noun on left" followed by noun cancels)

**Identity:** `1 · X = X = X · 1`

**General pattern:**
- `X · Xʳ → 1` (right cancellation)
- `Xˡ · X → 1` (left cancellation)

### Grammaticality as Type Reduction

A sequence of words is **grammatical** if and only if:
1. Assign types to each word
2. Concatenate the types (tensor product)
3. Apply reduction rules
4. Result reduces to `S`

## Example: "Alice loves Bob"

### Step 1: Assign Types

```
Alice : N           (noun)
loves : Nʳ · S · Nˡ (transitive verb: takes subject left, object right, produces S)
Bob   : N           (noun)
```

### Step 2: Concatenate

```
N · (Nʳ · S · Nˡ) · N
```

### Step 3: Reduce

```
N · (Nʳ · S · Nˡ) · N
    └──┬──┘
       1
= 1 · S · Nˡ · N
= S · Nˡ · N
      └──┬──┘
         1
= S · 1
= S ✓
```

### String Diagram View

```
Alice    loves      Bob
  │        │          │
  N    Nʳ  S  Nˡ      N
  │    │      │       │
  └────┘      └───────┘
       ↓           ↓
       1           1

       S ← Final output
```

The curved lines represent the reductions (cup morphisms in category theory).

## More Examples

### Intransitive Verb: "Alice runs"

```
Alice : N
runs  : Nʳ · S     (takes subject left, produces S)

Concatenated: N · Nʳ · S
              └──┬──┘
                 1
Result: S ✓
```

### Adjective: "big dog"

```
big : N · Nˡ       (modifies noun on right)
dog : N

Concatenated: N · Nˡ · N
              └──┬──┘
                 1
Result: N (noun phrase, not sentence)
```

### Determiner: "the cat"

```
the : N · Nˡ       (turns noun into noun phrase)
cat : N

Concatenated: N · Nˡ · N
Result: N ✓
```

### Complex: "Alice sees the big cat"

```
Alice : N
sees  : Nʳ · S · Nˡ
the   : N · Nˡ
big   : N · Nˡ
cat   : N

Concatenated: N · (Nʳ · S · Nˡ) · (N · Nˡ) · (N · Nˡ) · N

Reductions (right to left in object position):
N · Nˡ · N → N · 1 → N (for "big cat")
N · Nˡ · N → N · 1 → N (for "the [big cat]")
N · (Nʳ · S · Nˡ) · N → S (main structure)

Result: S ✓
```

## Why This Matters for ML

### Reductions = Wire Contractions

In a tensor network interpretation:
- Each word is a tensor
- Types are tensor indices
- **Reductions tell us which indices to contract**

```
Alice ⊗ loves ⊗ Bob
  ↓       ↓       ↓
 [v]    [M]     [w]
  ↓       ↓       ↓
  n    n×s×n     n

Contract: v · M · w → scalar (sentence meaning)
```

### DisCoCat Pipeline

1. **Parse** sentence to get type reductions
2. **Assign** vectors/tensors to words
3. **Contract** according to the reduction structure
4. **Result** = compositional sentence meaning

### Compositional Semantics

The pregroup structure ensures:
- Word order matters (N · Nʳ ≠ Nʳ · N)
- Meaning composition follows syntax
- Different parse structures give different meanings

## Pregroups as Categories

A pregroup is a **compact closed category** where:

**Objects:** Generated from basic types {N, S, ...} and their adjoints

**Morphisms:** Reductions (inequalities in the pregroup order)

**Composition:** Sequential reduction

**Monoidal structure:** Type concatenation (·)

**Compact closed structure:**
- Cups: `N · Nʳ → 1` and `Nˡ · N → 1`
- Caps: `1 → Nʳ · N` and `1 → N · Nˡ`

### String Diagrams

The cups and caps form the characteristic curved wires:

```
Cup (evaluation):     Cap (coevaluation):
    ┌───┐                   │
    │   │                 ┌─┴─┐
    N   Nʳ                Nʳ  N
```

## Connection to Lambek Calculus

Pregroups are a simplification of Lambek's syntactic calculus:
- Lambek: Full logical connectives (/, \, ·)
- Pregroup: Just adjoints and concatenation
- Both: Types as resources, parsing as proof search

**Trade-off:**
- Lambek: More expressive, computationally harder
- Pregroup: Simpler, polynomial-time parsing, sufficient for many applications

## Implementation Preview

```rust
// Types in a pregroup grammar
enum PregroupType {
    Basic(String),           // N, S, etc.
    LeftAdjoint(Box<Self>),  // Xˡ
    RightAdjoint(Box<Self>), // Xʳ
    Tensor(Vec<Self>),       // X · Y · Z
    Unit,                    // 1
}

// A typed word
struct TypedWord {
    word: String,
    typ: PregroupType,
}

// Check if two types can reduce
fn can_reduce(left: &PregroupType, right: &PregroupType) -> bool {
    match (left, right) {
        // X · Xʳ → 1
        (Basic(a), RightAdjoint(b)) => a == b.as_basic(),
        // Xˡ · X → 1
        (LeftAdjoint(a), Basic(b)) => a.as_basic() == b,
        _ => false,
    }
}
```

## Exercises

1. **Parse "the dog runs"**
   - Assign types: the : N·Nˡ, dog : N, runs : Nʳ·S
   - Show the reduction to S

2. **Parse "Alice thinks Bob runs"**
   - Hint: "thinks" takes a sentence complement: Nʳ·S·Sˡ

3. **Why is "loves Alice Bob" ungrammatical?**
   - Show the types don't reduce to S

4. **Design a type for "quickly"**
   - It modifies verbs: "Alice quickly runs"
   - What type makes this parse correctly?

## Summary

| Concept | Meaning |
|---------|---------|
| Basic type N, S | Noun, Sentence |
| Right adjoint Xʳ | Expects X on right |
| Left adjoint Xˡ | Expects X on left |
| X · Xʳ → 1 | Right reduction (cup) |
| Xˡ · X → 1 | Left reduction (cup) |
| Grammatical | Types reduce to S |
| Tensor network | Contract reduced indices |

## Reading

- Coecke, Sadrzadeh, Clark: "Mathematical Foundations for a Compositional Distributional Model of Meaning"
- Lambek: "Type Grammar Revisited"
- Preller & Sadrzadeh: "Bell States and Negative Sentences in the Distributed Model of Meaning"

## Next

Session 16: DisCoCat — Putting meanings on the wires (distributional semantics meets categorical grammar)
